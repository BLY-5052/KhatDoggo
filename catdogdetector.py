# -*- coding: utf-8 -*-
"""CatDogdetector.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YsiZF3OtYIG60e9bquEW_b6E7rQJUkBI
"""

import os
import numpy as np
import matplotlib.pyplot as plt
import tensorflow as tf
keras = tf.keras
import tensorflow_datasets as tfds

tfds.disable_progress_bar()
(raw_train, raw_validation, raw_test), metadata = tfds.load(
    'cats_vs_dogs',
    split=['train[:80%]', 'train[80%:90%]', 'train[90%:]'],
    with_info=True,
    as_supervised=True,
)

get_label_name = metadata.features['label'].int2str  # creates a function object that we can use to get labels

IMG_SIZE = 160 # All images will be resized to 160x160

def format_example(image, label):
  """
  returns an image that is reshaped to IMG_SIZE
  """
  image = tf.cast(image, tf.float32)
  image =  (image - 127.5) - 1

  image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))
  return image , label

train = raw_train.map(format_example)
validation = raw_validation.map(format_example)
test = raw_test.map(format_example)
test

BATCH_SIZE = 32
SHUFFLE_BUFFER_SIZE = 1000

train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)
validation_batches = validation.batch(BATCH_SIZE)
test_batches = test.batch(BATCH_SIZE)
train_batches

IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)

# Create the base model from the pre-trained model MobileNet V2
base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,
                                               include_top=False,
                                               weights='imagenet')

for image, _ in train_batches.take(1):
   pass

feature_batch = base_model(image)
print(feature_batch.shape)
base_model.trainable = False

global_average_layer = tf.keras.layers.GlobalAveragePooling2D()
prediction_layer = keras.layers.Dense(1)
model = tf.keras.Sequential([
  base_model,
  global_average_layer,
  prediction_layer ,
])

base_learning_rate = 0.0001
model.compile(optimizer='adam',
              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),
              metrics=['accuracy'])


loss0,accuracy0 = model.evaluate(validation_batches, steps = validation_steps)

# Now we can train it on our images
initial_epochs = 3
validation_steps=20
history = model.fit(train_batches,
                    epochs=initial_epochs,
                    validation_data=validation_batches)

acc = history.history['accuracy']
print(acc)

class_names = ['cat' , 'dog']
all_predictions=[]
for image_batch, label_batch in test_batches.as_numpy_iterator():
    predictions = model.predict_on_batch(image_batch).flatten()
    all_predictions.extend(predictions)

print('Predictions:\n', all_predictions)

a=int(input('choose an image number between 0 and 1700'))

for image, label in raw_test.skip(a).take(1):
  image = tf.cast(image, tf.float32)
  image =  (image/255.0)
  image = tf.image.resize(image, (160, 160))
  image = tf.expand_dims(image, axis=0)
  pred_new=model.predict(image)
  plt.figure()
  plt.imshow(image[0])
  print('this is the picture that you have chosen')

b=all_predictions[a]
if b<0:
  pred='khat :D'
else:
  pred='doggo >:)'
print('This is a ....',pred)